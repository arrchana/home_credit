{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Alternative) One-hot Encoding with Label Binarizer\n",
    "In the previous approach, we used Label Encoder to get numberic labels for our categorical values, and then added one-hot encoding for them using pandas. \n",
    "\n",
    "However, as we performed the transforms, we realize that the number of categories that appear in the test set are only a subset of all the possible categories in the training data. To tackle this, we removed those categories that never appeared in the test set. While this may work for cases where you know that these categories will never appear at test time. But, this is pretty bad if there are new test cases that have these unseen categorical variables. \n",
    "\n",
    "As a general rule, we must always try to use the full range of the features/variables in training our model whether or not they are tested in a given test-scenario. The more generic our model, the better its performance for unseen test cases. \n",
    "\n",
    "We use the following alternative approach to handle this case where future test cases where these categories might appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an attempt to build a baseline model with the given features (*i.e. no feature engineering or augmenting the training file with the other files*). The model explored is logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "# file system management\n",
    "import os\n",
    "\n",
    "# setting to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data files\n",
    "List all data files available from competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_path = './../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data files\n",
      "- application_test.csv\n",
      "- application_train.csv\n"
     ]
    }
   ],
   "source": [
    "print('Raw data files', *[f for f in os.listdir(raw_data_path) if not f.startswith('.')], sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is **application_train.csv**.\n",
    "Testing data is **application_test.csv**\n",
    "\n",
    "Training & Testing data shape - number of records & number of features/columns provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (307511, 122)\n",
      "Testing data shape (48744, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "              ...              FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
       "0             ...                             0                0   \n",
       "1             ...                             0                0   \n",
       "2             ...                             0                0   \n",
       "3             ...                             0                0   \n",
       "4             ...                             0                0   \n",
       "\n",
       "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                0                0                        0.0   \n",
       "1                0                0                        0.0   \n",
       "2                0                0                        0.0   \n",
       "3                0                0                        NaN   \n",
       "4                0                0                        0.0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                       0.0                         0.0   \n",
       "1                       0.0                         0.0   \n",
       "2                       0.0                         0.0   \n",
       "3                       NaN                         NaN   \n",
       "4                       0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        NaN                        NaN   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         1.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         NaN  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(raw_data_path, 'application_train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(raw_data_path, 'application_test.csv'))\n",
    "\n",
    "print(\"Training data shape\", train_data.shape)\n",
    "print(\"Testing data shape\", test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data has 307511 records, each of which is a loan application. Each record has 122 features. \n",
    "\n",
    "Testing data is considerably smaller, it has all features except the target column which is the variable to be predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know about the types of features available. Numerical variables (Integer and float) can be directly used for model building. Pandas reads in other types of variables as objects (string, character, etc) which are categorical variables that need to be converted to a form suited for model building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    65\n",
       "int64      41\n",
       "object     16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total applications  307511\n",
      "unique applicants  (307511,)\n"
     ]
    }
   ],
   "source": [
    "print(\"total applications \",train_data['SK_ID_CURR'].count())\n",
    "print(\"unique applicants \",train_data['SK_ID_CURR'].unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this means each applicant has only one application in the dataset. this will be useful to know later when we select the type of cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object type columns\n",
    "Number of unique values (potentially, classes or categories) in each object column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE             2\n",
       "CODE_GENDER                    3\n",
       "FLAG_OWN_CAR                   2\n",
       "FLAG_OWN_REALTY                2\n",
       "NAME_TYPE_SUITE                7\n",
       "NAME_INCOME_TYPE               8\n",
       "NAME_EDUCATION_TYPE            5\n",
       "NAME_FAMILY_STATUS             6\n",
       "NAME_HOUSING_TYPE              6\n",
       "OCCUPATION_TYPE               18\n",
       "WEEKDAY_APPR_PROCESS_START     7\n",
       "ORGANIZATION_TYPE             58\n",
       "FONDKAPREMONT_MODE             4\n",
       "HOUSETYPE_MODE                 3\n",
       "WALLSMATERIAL_MODE             7\n",
       "EMERGENCYSTATE_MODE            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>School</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>Block</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>Religion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY NAME_TYPE_SUITE  \\\n",
       "0         Cash loans           M            N               Y   Unaccompanied   \n",
       "1         Cash loans           F            N               N          Family   \n",
       "2    Revolving loans           M            Y               Y   Unaccompanied   \n",
       "3         Cash loans           F            N               Y   Unaccompanied   \n",
       "4         Cash loans           M            N               Y   Unaccompanied   \n",
       "\n",
       "  NAME_INCOME_TYPE            NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0          Working  Secondary / secondary special  Single / not married   \n",
       "1    State servant               Higher education               Married   \n",
       "2          Working  Secondary / secondary special  Single / not married   \n",
       "3          Working  Secondary / secondary special        Civil marriage   \n",
       "4          Working  Secondary / secondary special  Single / not married   \n",
       "\n",
       "   NAME_HOUSING_TYPE OCCUPATION_TYPE WEEKDAY_APPR_PROCESS_START  \\\n",
       "0  House / apartment        Laborers                  WEDNESDAY   \n",
       "1  House / apartment      Core staff                     MONDAY   \n",
       "2  House / apartment        Laborers                     MONDAY   \n",
       "3  House / apartment        Laborers                  WEDNESDAY   \n",
       "4  House / apartment      Core staff                   THURSDAY   \n",
       "\n",
       "        ORGANIZATION_TYPE FONDKAPREMONT_MODE  HOUSETYPE_MODE  \\\n",
       "0  Business Entity Type 3   reg oper account  block of flats   \n",
       "1                  School   reg oper account  block of flats   \n",
       "2              Government                NaN             NaN   \n",
       "3  Business Entity Type 3                NaN             NaN   \n",
       "4                Religion                NaN             NaN   \n",
       "\n",
       "  WALLSMATERIAL_MODE EMERGENCYSTATE_MODE  \n",
       "0       Stone, brick                  No  \n",
       "1              Block                  No  \n",
       "2                NaN                 NaN  \n",
       "3                NaN                 NaN  \n",
       "4                NaN                 NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize what these categories look like \n",
    "train_data.select_dtypes('object').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes before transform\n",
      "(307511, 122)\n",
      "(48744, 121)\n",
      "Transforming column  NAME_CONTRACT_TYPE  with categories  ['Cash loans' 'Revolving loans']\n",
      "Transforming column  CODE_GENDER  with categories  ['M' 'F' 'XNA']\n",
      "Transforming column  FLAG_OWN_CAR  with categories  ['N' 'Y']\n",
      "Transforming column  FLAG_OWN_REALTY  with categories  ['Y' 'N']\n",
      "Transforming column  NAME_TYPE_SUITE  with categories  ['Unaccompanied' 'Family' 'Spouse, partner' 'Children' 'Other_A' nan\n",
      " 'Other_B' 'Group of people']\n",
      "Transforming column  NAME_INCOME_TYPE  with categories  ['Working' 'State servant' 'Commercial associate' 'Pensioner' 'Unemployed'\n",
      " 'Student' 'Businessman' 'Maternity leave']\n",
      "Transforming column  NAME_EDUCATION_TYPE  with categories  ['Secondary / secondary special' 'Higher education' 'Incomplete higher'\n",
      " 'Lower secondary' 'Academic degree']\n",
      "Transforming column  NAME_FAMILY_STATUS  with categories  ['Single / not married' 'Married' 'Civil marriage' 'Widow' 'Separated'\n",
      " 'Unknown']\n",
      "Transforming column  NAME_HOUSING_TYPE  with categories  ['House / apartment' 'Rented apartment' 'With parents'\n",
      " 'Municipal apartment' 'Office apartment' 'Co-op apartment']\n",
      "Transforming column  OCCUPATION_TYPE  with categories  ['Laborers' 'Core staff' 'Accountants' 'Managers' nan 'Drivers'\n",
      " 'Sales staff' 'Cleaning staff' 'Cooking staff' 'Private service staff'\n",
      " 'Medicine staff' 'Security staff' 'High skill tech staff'\n",
      " 'Waiters/barmen staff' 'Low-skill Laborers' 'Realty agents' 'Secretaries'\n",
      " 'IT staff' 'HR staff']\n",
      "Transforming column  WEEKDAY_APPR_PROCESS_START  with categories  ['WEDNESDAY' 'MONDAY' 'THURSDAY' 'SUNDAY' 'SATURDAY' 'FRIDAY' 'TUESDAY']\n",
      "Transforming column  ORGANIZATION_TYPE  with categories  ['Business Entity Type 3' 'School' 'Government' 'Religion' 'Other' 'XNA'\n",
      " 'Electricity' 'Medicine' 'Business Entity Type 2' 'Self-employed'\n",
      " 'Transport: type 2' 'Construction' 'Housing' 'Kindergarten'\n",
      " 'Trade: type 7' 'Industry: type 11' 'Military' 'Services'\n",
      " 'Security Ministries' 'Transport: type 4' 'Industry: type 1' 'Emergency'\n",
      " 'Security' 'Trade: type 2' 'University' 'Transport: type 3' 'Police'\n",
      " 'Business Entity Type 1' 'Postal' 'Industry: type 4' 'Agriculture'\n",
      " 'Restaurant' 'Culture' 'Hotel' 'Industry: type 7' 'Trade: type 3'\n",
      " 'Industry: type 3' 'Bank' 'Industry: type 9' 'Insurance' 'Trade: type 6'\n",
      " 'Industry: type 2' 'Transport: type 1' 'Industry: type 12' 'Mobile'\n",
      " 'Trade: type 1' 'Industry: type 5' 'Industry: type 10' 'Legal Services'\n",
      " 'Advertising' 'Trade: type 5' 'Cleaning' 'Industry: type 13'\n",
      " 'Trade: type 4' 'Telecom' 'Industry: type 8' 'Realtor' 'Industry: type 6']\n",
      "Transforming column  FONDKAPREMONT_MODE  with categories  ['reg oper account' nan 'org spec account' 'reg oper spec account'\n",
      " 'not specified']\n",
      "Transforming column  HOUSETYPE_MODE  with categories  ['block of flats' nan 'terraced house' 'specific housing']\n",
      "Transforming column  WALLSMATERIAL_MODE  with categories  ['Stone, brick' 'Block' nan 'Panel' 'Mixed' 'Wooden' 'Others' 'Monolithic']\n",
      "Transforming column  EMERGENCYSTATE_MODE  with categories  ['No' nan 'Yes']\n",
      "16 columns were label encoded.\n",
      "shapes after transform\n",
      "(307511, 249)\n",
      "(48744, 248)\n"
     ]
    }
   ],
   "source": [
    "print(\"shapes before transform\")\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# Label Binarizer creates a transformation for categorical variables to One-Hot Encoding \n",
    "lb = LabelBinarizer()\n",
    "lb_count = 0 #number of columns that are label encoded\n",
    "\n",
    "# Iterate through all columns \n",
    "transformed_train = train_data\n",
    "transformed_test  = test_data\n",
    "\n",
    "for col in train_data:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        print(\"Transforming column \", col ,\" with categories \", train_data[col].unique())\n",
    "\n",
    "        # train the label encoder on the training data\n",
    "        lb.fit(train_data[col].astype(str))\n",
    "        \n",
    "        # transform the column on both training and testing data\n",
    "        transformed_col = lb.transform(train_data[col].astype(str))\n",
    "        # removing the original column from the dataframe and adding the new transformed columns\n",
    "        temp_df = pd.DataFrame(transformed_col)\n",
    "        transformed_train.drop([col],1,inplace=True)\n",
    "        transformed_train = transformed_train.join(temp_df, how='outer', rsuffix = col)\n",
    "    \n",
    "        transformed_col = lb.transform(test_data[col].astype(str))\n",
    "        temp_df = pd.DataFrame(transformed_col)\n",
    "        transformed_test.drop([col],1,inplace=True)\n",
    "        transformed_test = transformed_test.join(temp_df, how='outer', rsuffix = col)\n",
    "        \n",
    "        lb_count += 1\n",
    "            \n",
    "            \n",
    "print('{} columns were label encoded.'.format(lb_count))\n",
    "print(\"shapes after transform\")\n",
    "print(transformed_train.shape)\n",
    "print(transformed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = transformed_train\n",
    "test_data = transformed_test\n",
    "train_labels = train_data['TARGET']\n",
    "train_data.drop(['TARGET'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data \n",
    "- Filling in missing values via imputation\n",
    "- Feature scaling / normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (307511, 248)\n",
      "Testing data shape (48744, 248)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "# Drop the target column from training data \n",
    "if 'TARGET' in train_data:\n",
    "    train_set = train_data.drop(columns = ['TARGET'])\n",
    "else:\n",
    "    train_set = train_data.copy()\n",
    "    \n",
    "features = list(train_set.columns)\n",
    "\n",
    "# Copy test data\n",
    "test_set = test_data.copy()\n",
    "\n",
    "# Impute missing values with median\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "\n",
    "# Fit on the training data\n",
    "imputer.fit(train_set)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "train_set = imputer.transform(train_set)\n",
    "test_set = imputer.transform(test_set)\n",
    "\n",
    "# Repeat above 2 steps with scaler\n",
    "scaler.fit(train_set)\n",
    "train_set = scaler.transform(train_set)\n",
    "test_set = scaler.transform(test_set)\n",
    "\n",
    "print(\"Training data shape\", train_set.shape)\n",
    "print(\"Testing data shape\", test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation testing\n",
    "hold out part of the training set to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# creating a validation set that is 40% of the original training set. \n",
    "# the remaining 60% would be used for model building\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_set, train_labels, test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (184506, 248)\n",
      "Validation set shape (123005, 248)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape\", x_train.shape)\n",
    "print(\"Validation set shape\", x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73125991 0.73148378 0.72592415 0.73025699 0.73465602]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn built-in toolkit for cross-validation \n",
    "from sklearn.model_selection import KFold,cross_validate, cross_val_score\n",
    "\n",
    "\n",
    "# Create model with a specified regularization parameter\n",
    "log_reg = LogisticRegression(C = 0.001)\n",
    "\n",
    "# Train on the training data\n",
    "scores = cross_val_score(log_reg, train_set, train_labels, scoring = 'roc_auc',cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.7307161687391719\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC score : 0.7272078316008892\n",
      "Validation AUC score : 0.7303015056863118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# We need to fit again, as cross_val_score clones the classifier internally. \n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for the validation set\n",
    "pred_val = log_reg.predict_proba(x_val)[:, 1]\n",
    "pred_train = log_reg.predict_proba(x_train)[:, 1]\n",
    "\n",
    "print('Training AUC score : {}'.format(roc_auc_score(y_train, pred_train)))\n",
    "print('Validation AUC score : {}'.format(roc_auc_score(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning\n",
    "\n",
    "So far, we used the default parameter settings to train our LogisticRegression estimator. Now, let's change the parameter C in regular intervals & identify the one which gives the best esimator/classifier. This process of selecting the best model given a training set is called model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C : 0.0001\n",
      "training :  0.6839404181108345\n",
      "testing :  0.6836213592211109\n",
      "C : 0.001\n",
      "training :  0.7317297182966866\n",
      "testing :  0.7306923195119734\n",
      "C : 0.01\n",
      "training :  0.742513651969831\n",
      "testing :  0.7407780413467666\n",
      "C : 0.1\n",
      "training :  0.7452928341970464\n",
      "testing :  0.7428025783728158\n",
      "C : 0.4\n",
      "training :  0.7470583707436399\n",
      "testing :  0.744241999268342\n"
     ]
    }
   ],
   "source": [
    "params = []\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "\n",
    "for c in [0.0001,0.001,0.01,0.1,0.4,0.7,1.0]:\n",
    "    clf = LogisticRegression(C = c)\n",
    "    params.append(c)\n",
    "    tss = []\n",
    "    tes = []\n",
    "    for train, test in KFold(n_splits=5).split(train_set):\n",
    "        clf.fit(train_set[train], train_labels[train])\n",
    "\n",
    "        pred_train = clf.predict_proba(train_set[train])[:,1]\n",
    "        pred_test = clf.predict_proba(train_set[test])[:, 1]\n",
    "        tss.append(roc_auc_score(train_labels[train], pred_train))\n",
    "        tes.append(roc_auc_score(train_labels[test], pred_test))\n",
    "    print(\"C :\", c)\n",
    "    print(\"training : \",sum(tss)/5)\n",
    "    print(\"testing : \", sum(tes)/5)\n",
    "    train_scores.append(sum(tss)/5)\n",
    "    val_scores.append(sum(tes)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Plot the training and testing \n",
    "plt.plot(params, train_scores, color='blue', label='training score')\n",
    "plt.plot(params, val_scores , color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('score');\n",
    "print(\"C : \",params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "From the graph above we see that the only change in performance is brought when changing `C` from `0.0001` to `0.001`.\n",
    "\n",
    "Since we already set our `C = 0.001` in our first model generation stage, we do not need to re-do this step. But, if we had found a better set of parameters to use, at this stage, we will re-train the model with the new parameters and use that for our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "Target - value of 1 indicates client with payment difficulties\n",
    "\n",
    "Predict the probabilities of not repaying a loan. \n",
    "\n",
    "Model *predict_proba* method returns the probability of belonging to each of the target variable classes. Since we want the probability of not repaying a loan, we need to select the second column. \n",
    "\n",
    "(There are only 2 possible values to the Target column, so the sum of these probabilities would add to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for the test data\n",
    "log_reg_pred = log_reg.predict_proba(test_set)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.171014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.048824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.058039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.135355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.056148\n",
       "1      100005  0.171014\n",
       "2      100013  0.048824\n",
       "3      100028  0.058039\n",
       "4      100038  0.135355"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compose the submission csv\n",
    "submission = test_data[['SK_ID_CURR']]\n",
    "submission['TARGET'] = log_reg_pred\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180628-153847\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the submission to a csv file\n",
    "submission.to_csv('./../data/output/submission_'+str(timestr)+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
